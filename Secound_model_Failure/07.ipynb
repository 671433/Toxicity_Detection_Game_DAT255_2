{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac334470-3d3c-4f9b-a756-48e802a9025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.0\n",
      "Num GPUs Available: 1\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50e5c43-9da8-465b-a69d-5adda0c88bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2374287241800410951\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1405950158\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11153364547114261673\n",
      "physical_device_desc: \"device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0ced4c-f90c-4282-bbec-8d80aa1f6e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth set for GPU.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth set for GPU.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7c8a5e-8a15-4b11-943f-60004780518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tamer\\anaconda3\\envs\\deep\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy matplotlib pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff07a35-e4e6-416b-a1cd-0afb9ec75bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "texts = np.load('clean_texts.npy', allow_pickle=True)\n",
    "labels = np.load('clean_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec3d0d92-0735-485a-a9e6-94837f73badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 1804512\n",
      "Example: this is so cool its like would you want your mother to read this really great idea well done\n",
      "Number of texts: 1804512\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of texts:\", len(texts))\n",
    "print(\"Example:\", texts[0])\n",
    "print(\"Number of texts:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b7d377-eb62-4725-bec4-793d780109d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(type(texts))  \n",
    "print(isinstance(texts, np.ndarray)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e0b3dff-de29-447f-b329-71df730d7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS= 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd216cd8-4846-496c-8bae-6a467886129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Create the vectorizer\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_WORDS,\n",
    "    output_sequence_length=200,  \n",
    "    output_mode='int'\n",
    ")\n",
    "\n",
    "# Vectorizer training on texts\n",
    "vectorizer.adapt(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ead08aca-0864-4a14-bc93-ed75ccf53c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int64, numpy=\n",
       "array([3506, 1230,    1,    7, 1328,    1,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer('Hello, Deep learing is non eazy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a53d2d-fd61-4202-8e9f-ead47aec5c41",
   "metadata": {},
   "source": [
    "# Convert data to Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((texts, labels))\n",
    "\n",
    "dataset = dataset.map(lambda x, y: (vectorizer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Data organization\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(10000)\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c26eb31-91ac-4cfa-95ff-9ea2c548b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cache and/or shuffle (temporarily for testing):\n",
    "dataset = tf.data.Dataset.from_tensor_slices((texts, labels))\n",
    "dataset = dataset.map(lambda x, y: (vectorizer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d40aecb-8741-44a3-9d88-a6def886db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train / val / test\n",
    "dataset_size = len(list(dataset))  \n",
    "train_size = int(dataset_size * 0.7)\n",
    "val_size = int(dataset_size * 0.2)\n",
    "\n",
    "train = dataset.take(train_size)\n",
    "val = dataset.skip(train_size).take(val_size)\n",
    "test = dataset.skip(train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f540e9-43ce-44b1-8aa2-d3a808bc72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4c3504b-ae83-4d30-a819-aa1b4f31edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(200,)))\n",
    "# Create the embedding layer\n",
    "model.add(Embedding(input_dim=MAX_WORDS+1, output_dim=32, input_length=200))\n",
    "# Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "# Feature extractor Fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Final layer\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74c79ca3-dbf3-47b3-ae0f-67178b69f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65140aa-bdca-4c24-96ed-37e45616a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f0cfd-8898-4580-b9a2-04f940c0f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8058f-1f66-4875-94a6-4c54e6c42522",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, \n",
    "                    epochs=4, \n",
    "                    validation_data=val,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stop]       \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94b475-1ffa-4c9f-8b36-eff87c906f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')\n",
    "print(\"Model saved successfully \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a209f-fa6e-458e-9a82-b9772687e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.title(\"Training History\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss / Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d4e8b-cc61-417f-b0dd-2516efbf3036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (toxicityPython39)",
   "language": "python",
   "name": "toxicitypython39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
