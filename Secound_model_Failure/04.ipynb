{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445cd47e-8507-48c2-a538-9d1d308dd217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (2.0.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 15.2 MB/s eta 0:00:00\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 11.4 MB/s eta 0:00:00\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     ------------------------------------- 294.9/294.9 KB 17.8 MB/s eta 0:00:00\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "     ------------------------------------- 491.2/491.2 KB 30.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (2.19.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "     --------------------------------------- 11.2/11.2 MB 27.3 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     ------------------------------------- 509.2/509.2 KB 16.1 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     ------------------------------------- 347.8/347.8 KB 21.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 28.7 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "     ---------------------------------------- 111.1/111.1 KB ? eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 28.1 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "     ------------------------------------- 211.8/211.8 KB 12.6 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.8/55.8 KB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting huggingface-hub>=0.24.0\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "     ------------------------------------- 481.4/481.4 KB 10.0 MB/s eta 0:00:00\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-19.0.1-cp39-cp39-win_amd64.whl (25.5 MB)\n",
      "     --------------------------------------- 25.5/25.5 MB 13.7 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.16-cp39-cp39-win_amd64.whl (442 kB)\n",
      "     ------------------------------------- 442.4/442.4 KB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "     -------------------------------------- 116.3/116.3 KB 6.6 MB/s eta 0:00:00\n",
      "Collecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 KB 4.6 MB/s eta 0:00:00\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 KB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "     ------------------------------------- 183.9/183.9 KB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "     --------------------------------------- 46.2/46.2 MB 16.8 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------- 301.8/301.8 KB 18.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.1-cp39-cp39-win_amd64.whl (45 kB)\n",
      "     ---------------------------------------- 45.7/45.7 KB ? eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-win_amd64.whl (51 kB)\n",
      "     ---------------------------------------- 51.8/51.8 KB ? eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.19.0-cp39-cp39-win_amd64.whl (93 kB)\n",
      "     ---------------------------------------- 93.2/93.2 KB ? eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.4.3-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: rich in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: optree in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: namex in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\tamer\\onedrive - høgskulen på vestlandet\\dokumenter\\3 år\\dat255 deep learning\\toxicity2\\toxicitypython39\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, threadpoolctl, scipy, pyparsing, pyarrow, propcache, pillow, multidict, kiwisolver, joblib, importlib-resources, fsspec, frozenlist, fonttools, filelock, dill, cycler, contourpy, async-timeout, aiohappyeyeballs, yarl, scikit-learn, pandas, multiprocess, matplotlib, huggingface-hub, aiosignal, seaborn, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 async-timeout-5.0.1 contourpy-1.3.0 cycler-0.12.1 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 fonttools-4.57.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.30.2 importlib-resources-6.5.2 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.9.4 multidict-6.4.3 multiprocess-0.70.16 pandas-2.2.3 pillow-11.2.1 propcache-0.3.1 pyarrow-19.0.1 pyparsing-3.2.3 pytz-2025.2 scikit-learn-1.6.1 scipy-1.13.1 seaborn-0.13.2 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.2 xxhash-3.5.0 yarl-1.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\tamer\\OneDrive - Høgskulen på Vestlandet\\Dokumenter\\3 År\\DAT255 Deep learning\\toxicity2\\toxicityPython39\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib seaborn datasets tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39433169-152c-48f8-bd1e-b5524f108075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ede6f0-bfd7-467d-877e-1c039b958636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\", 'toxicity': 0.0, 'severe_toxicity': 0.0, 'obscene': 0.0, 'threat': 0.0, 'insult': 0.0, 'identity_attack': 0.0, 'sexual_explicit': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Load civil_comments dataset\n",
    "dataset = load_dataset(\"google/civil_comments\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29746f02-dd23-4ea5-b8d0-b4df89f6d85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxicity  \\\n",
       "0  This is so cool. It's like, 'would you want yo...  0.000000   \n",
       "1  Thank you!! This would make my life a lot less...  0.000000   \n",
       "2  This is such an urgent design problem; kudos t...  0.000000   \n",
       "3  Is this something I'll be able to install on m...  0.000000   \n",
       "4               haha you guys are a bunch of losers.  0.893617   \n",
       "\n",
       "   severe_toxicity  obscene  threat   insult  identity_attack  sexual_explicit  \n",
       "0         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
       "1         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
       "2         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
       "3         0.000000      0.0     0.0  0.00000         0.000000              0.0  \n",
       "4         0.021277      0.0     0.0  0.87234         0.021277              0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "048e9953-9fe0-4712-b4e6-8b6c0876681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          This is so cool. It's like, 'would you want yo...\n",
      "1          Thank you!! This would make my life a lot less...\n",
      "2          This is such an urgent design problem; kudos t...\n",
      "3          Is this something I'll be able to install on m...\n",
      "4                       haha you guys are a bunch of losers.\n",
      "                                 ...                        \n",
      "1804869    Maybe the tax on \"things\" would be collected w...\n",
      "1804870    What do you call people who STILL think the di...\n",
      "1804871    thank you ,,,right or wrong,,, i am following ...\n",
      "1804872    Anyone who is quoted as having the following e...\n",
      "1804873    Students defined as EBD are legally just as di...\n",
      "Name: text, Length: 1804874, dtype: object\n",
      "[[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.03030303 0.03030303 0.         0.62121212 0.04545455 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "comment_text = df['text']\n",
    "lables = df[df.columns[2:]].values\n",
    "\n",
    "print(comment_text)\n",
    "print(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814e1e73-3f7a-44b7-b2fe-dcc831ffe4c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__RaggedTensorToTensor_num_row_partition_tensors_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[1804874,1800] and type int64 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:RaggedTensorToTensor] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs=array([\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n       \"Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!\",\n       'This is such an urgent design problem; kudos to you for taking it on. Very impressive!',\n       ..., 'thank you ,,,right or wrong,,, i am following your advice',\n       'Anyone who is quoted as having the following exchange, even if apocryphal, would have received my vote! \\n\\nBessie Braddock: \"Winston, you are drunk, and what’s more you are disgustingly drunk.\"\\nWinston Churchill: \"Bessie, my dear, you are ugly, and what’s more, you are disgustingly ugly. But tomorrow I shall be sober and you will still be disgustingly ugly.\"',\n       'Students defined as EBD are legally just as disabled and eligible for special services as a developmentally disabled or physically disabled student. \\n\\nEMOTIONAL AND BEHAVIORAL DISORDER (EBD).\\nDefinition. \\nAn emotional and behavioral disorder is an emotional disability characterized by the following: \\n(i)  An inability to build or maintain satisfactory interpersonal relationships with peers and/or teachers.  For preschool-age children, this would include \\nother care providers.  \\n(ii) An inability to learn which cannot be adequately explained by intellectual,sensory or health factors.  \\n(iii) A consistent or chronic inappropriate type of behavior or feelings under normal conditions. \\n(iv) A displayed pervasive mood of unhappiness or depression. \\n(v)  A displayed tendency to develop physical symptoms, pains or unreasonable fears associated with personal or school problem\\ns.  [34 C.F.R. § 300.8(c)(4)(i)(A – E)]'],\n      dtype=object)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TextVectorization(max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, output_sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1800\u001b[39m, output_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m vectorizer\u001b[38;5;241m.\u001b[39madapt(comment_text\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m----> 3\u001b[0m vectorized_text \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive - Høgskulen på Vestlandet\\Dokumenter\\3 År\\DAT255 Deep learning\\toxicity2\\toxicityPython39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\OneDrive - Høgskulen på Vestlandet\\Dokumenter\\3 År\\DAT255 Deep learning\\toxicity2\\toxicityPython39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6006\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6005\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6006\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__RaggedTensorToTensor_num_row_partition_tensors_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[1804874,1800] and type int64 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:RaggedTensorToTensor] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs=array([\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n       \"Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!\",\n       'This is such an urgent design problem; kudos to you for taking it on. Very impressive!',\n       ..., 'thank you ,,,right or wrong,,, i am following your advice',\n       'Anyone who is quoted as having the following exchange, even if apocryphal, would have received my vote! \\n\\nBessie Braddock: \"Winston, you are drunk, and what’s more you are disgustingly drunk.\"\\nWinston Churchill: \"Bessie, my dear, you are ugly, and what’s more, you are disgustingly ugly. But tomorrow I shall be sober and you will still be disgustingly ugly.\"',\n       'Students defined as EBD are legally just as disabled and eligible for special services as a developmentally disabled or physically disabled student. \\n\\nEMOTIONAL AND BEHAVIORAL DISORDER (EBD).\\nDefinition. \\nAn emotional and behavioral disorder is an emotional disability characterized by the following: \\n(i)  An inability to build or maintain satisfactory interpersonal relationships with peers and/or teachers.  For preschool-age children, this would include \\nother care providers.  \\n(ii) An inability to learn which cannot be adequately explained by intellectual,sensory or health factors.  \\n(iii) A consistent or chronic inappropriate type of behavior or feelings under normal conditions. \\n(iv) A displayed pervasive mood of unhappiness or depression. \\n(v)  A displayed tendency to develop physical symptoms, pains or unreasonable fears associated with personal or school problem\\ns.  [34 C.F.R. § 300.8(c)(4)(i)(A – E)]'],\n      dtype=object)"
     ]
    }
   ],
   "source": [
    "vectorizer = TextVectorization(max_tokens=10000, output_sequence_length=1800, output_mode='int')\n",
    "vectorizer.adapt(comment_text.values)\n",
    "vectorized_text = vectorizer(comment_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e4850-dab1-4642-8a18-7ae694e5c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbd6a5-93e2-4ca8-b0ce-9b4be8e1a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, lables))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(1804874)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (toxicityPython39)",
   "language": "python",
   "name": "toxicitypython39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
